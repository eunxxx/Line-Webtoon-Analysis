{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pyperclip\n",
    "\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "import seaborn as sns\n",
    "\n",
    "import koreanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "font_path = '/Users/jieunlee/Documents/3_TECH!T_202305/TECH!T_dataton/nanum-barun-gothic/NanumBarunGothic.ttf'  # 각자 경로에 맞게\n",
    "fontprop = fm.FontProperties(fname=font_path, size=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Crawling_LineWebtoon(태국)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.webtoons.com/th/originals\n",
      "ติดตามและอัปเดต การ์ตูน ออนไลน์ ฟรี | LINE WEBTOON\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.webtoons.com/th/originals'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "print(driver.current_url)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ประจำวัน(요일별전체웹툰)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['제목', '작가', '장르', '좋아요수', '조회수', '구독수', '별점', '회차'])\n",
    "# 'OSMU여부', '작가전작개수', '한국작품여부', '한국제목'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 9): # 월요일 2 ~ 일요일 8\n",
    "\n",
    "    count = [47, 57, 54, 53, 50, 51, 57]\n",
    "\n",
    "    for j in range(1, count[i-2]+1): # 요일별 처음 ~ 끝\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, 0)\") \n",
    "\n",
    "        date_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/h2/a\"\"\")\n",
    "        date_button.click()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        title = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/div/p[1]\"\"\").text\n",
    "        author = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/div/p[2]\"\"\").text\n",
    "        genre = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/p[1]\"\"\").text\n",
    "        like = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/p[2]/em\"\"\").text\n",
    "\n",
    "        # 상세페이지 들어가기\n",
    "        detail_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a\"\"\")\n",
    "        detail_button.click()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        view = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_asideDetail\"]/ul/li[1]/em\"\"\").text\n",
    "        subscribe = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_asideDetail\"]/ul/li[2]/em\"\"\").text\n",
    "        starscore = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_starScoreAverage\"]\"\"\").text\n",
    "        \n",
    "        req = requests.get(driver.current_url)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        episode = soup.find_all(class_='tx')[0].text.replace('#', '')\n",
    "\n",
    "        df.loc[len(df)] = [title, author, genre, like, view, subscribe, starscore, episode]\n",
    "\n",
    "        print(i, j, title)\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 상세페이지 나오기\n",
    "        driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('crawling_요일.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ฟรีทุกวัน(전체매일+웹툰)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=['제목', '작가', '장르', '좋아요수', '조회수', '구독수', '별점', '회차'])\n",
    "# 'OSMU여부', '작가전작개수', '한국작품여부', '한국제목'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456 Lovely Debor ผมจะยอมเป็นสามีคุณเพื่อใช้หนี้\n",
      "457 Age Matters วุ่นรักต่างวัย เจ้านายสุดแสบ\n",
      "458 Heart Rate จังหวะนี้ผีหรือรัก\n",
      "459 ร้านหนังสือแห่งรัก\n",
      "460 Utopia ลำนำรักเจ้าชายในฝัน ตอน ศึกรักบัลลังก์พิศวาส\n",
      "461 ไอดอลหนุ่มแปลงโฉม\n",
      "462 คนคนนี้ที่เพื่อนฉันรัก\n",
      "463 อุนจิ เรื่องวุ่นของพระเอกหมาๆ\n",
      "464 แอปลับ แอบรัก\n",
      "465 Why me เมื่อฉันเกิดใหม่เป็นนางร้ายนิยายวาย\n",
      "466 นิยายรักของปีศาจ\n",
      "467 True Love's Kiss จูบรัก...พิทักษ์ความทรงจำ\n",
      "468 Standard Human\n",
      "469 LOVE AT FIRST JOB งานยุ่งวุ่นรัก\n",
      "470 โอปป้า โชซอนสไตล์\n",
      "471 Lost in 2152 อนาคตทดลองรัก ทดสอบใจ\n",
      "472 สายใยรักอุดมคติ\n",
      "473 SUPER CASTING: BTS\n",
      "474 Tooth fairy ลิขิตรักไซซ์ XL\n",
      "475 ผมถูกรักแรกไล่ฆ่า\n",
      "476 ห้ามหัวใจไม่ให้รักเธอ\n",
      "477 เพียงตะวันจันทร์เจ้าขา\n",
      "478 เก็บรักไว้ที่ปลายฟ้า\n",
      "479 After Rolling ฟิล์มร้อน อ้อนรัก\n",
      "480 Change to be best (boy) friend เมื่อเพื่อนของฉัน...\n",
      "481 อลวนคน (เคย) รัก\n",
      "482 Eggnoid\n",
      "483 อุบัติรักต้องคำสาป\n",
      "484 HOPEfully soon\n",
      "485 รักนี้ไม่มีรีทัช\n",
      "486 Honey Honey Wedding\n",
      "487 สาปศาลปรัมปรา\n",
      "488 แผนการรักของยัยมารร้าย\n",
      "489 บันทึกมึนๆ ของ Fastbeam\n",
      "490 ครัวคิลเลอร์\n",
      "491 World of Elemental ผจญภัยโลกเวทมนตร์\n",
      "492 รักนี้สะอาดเนี้ยบ\n",
      "493 คาปู้น้อยจอมเขมือบ\n",
      "494 STAY HOME STAY SAFE\n",
      "495 รวมเรื่องสั้นจากประตูสู่ดาว 2019\n",
      "496 Promise in LOVE สัญญาต้องเป็นสัญญา\n",
      "497 Chivalry\n",
      "498 Wonderful Day\n",
      "499 รวมเรื่องสั้นจากประตูสู่ดาว 2018\n",
      "500 Pastel รักนี้สีพาสเทล\n",
      "501 Couple on the Way\n",
      "502 รักนะ เจ้านายของผม\n",
      "503 งานเยอะ เรื่องแยะ\n",
      "504 Sweet EscapE\n",
      "505 คังบยอน\n",
      "506 มรดกของพ่อ\n",
      "507 ร่องรอยจากมือ\n",
      "508 Love on Track\n",
      "509 Ctrl + Z\n",
      "510 รู้สักนิดก่อนคิดจะรัก\n",
      "511 Fourth of July มีรักต้องประกาศ\n",
      "512 สาวน้อยร้อยช่าง\n",
      "513 เช็คพอยท์\n",
      "514 Pop-Up ตึ๊กตั๊ก!! รักทักมา\n",
      "515 เคล็ดไม่ลับสวยใสสไตล์เกาหลี\n",
      "516 ครัวแม่ดาชา ซีเคร็ทเซอร์วิส\n",
      "517 ผจญป่วน ก๊วนจอมเวท\n",
      "518 วาดเล่นๆ ดันเป็นเรื่อง\n",
      "519 Capo เหมียวหง่าวหลุดโลก\n",
      "520 ไซด์คิกส์ ฮีโร่ตัวรอง\n",
      "521 เล่าเรื่องพ่อ The Series\n",
      "522 แฟนเดย์..แฟนกันแค่วันเดียว\n",
      "523 Untold Love Stories\n",
      "524 Friendship เพื่อนกันนานเวอร์\n",
      "525 อัศวินทะลุมิติ\n",
      "526 1 Wish หนึ่งคำอธิษฐาน\n",
      "527 สตาร์วอร์ส\n",
      "528 THE DESTROYER เกิด/ฆ่า/อมตะ\n",
      "529 Shewsheep กินทั้งวัน ฝันยังเคี้ยว\n",
      "530 แมวขี้อ้อน . . . . . หมาขี้เหงา\n",
      "531 ชีวิตนี้ รสหวานขม\n",
      "532 ครัวแม่ดาชา\n",
      "533 จิงเกิ้ลจังเกิ้ล เพื่อนป่าฮาเฮ\n",
      "534 ฝีแปรงแย้มยิ้ม : ภาพเก่าๆ ของฉัน\n",
      "535 ฮาเร็ม ซะเมื่อไหร่กันเล่า!\n",
      "536 ตำนานทางรถไฟหลังโรงเรียน\n",
      "537 ซุปเปอร์คุณพ่อ\n",
      "538 ฝีแปรงแย้มยิ้ม\n",
      "539 ธรรมดาไดอารี่\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 540): \n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[1]/div/ul/li[2]/a\"\"\")\n",
    "    button.click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    title = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/div/p[1]\"\"\").text\n",
    "    author = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/div/p[2]\"\"\").text\n",
    "    genre = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/p[1]\"\"\").text\n",
    "    like = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/p[2]/em\"\"\").text\n",
    "\n",
    "    # 상세페이지 들어가기\n",
    "    detail_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a\"\"\")\n",
    "    detail_button.click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    view = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_asideDetail\"]/ul/li[1]/em\"\"\").text\n",
    "    subscribe = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_asideDetail\"]/ul/li[2]/em\"\"\").text\n",
    "    starscore = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_starScoreAverage\"]\"\"\").text\n",
    "    \n",
    "    req = requests.get(driver.current_url)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    episode = soup.find_all(class_='tx')[0].text.replace('#', '')\n",
    "\n",
    "    df2.loc[len(df2)] = [title, author, genre, like, view, subscribe, starscore, episode]\n",
    "\n",
    "    print(i, title)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 상세페이지 나오기\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('crawling_매일.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **concat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('crawling_요일.csv')\n",
    "data2 = pd.read_csv('crawling_매일.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([data1, data2])\n",
    "d.to_csv('crawling_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ประจำวัน(요일별전체웹툰)_연재시작일 및 마지막연재일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = pd.DataFrame(columns=['title', 'author', 'last_date', 'start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.webtoons.com/th/originals\n",
      "ติดตามและอัปเดต การ์ตูน ออนไลน์ ฟรี | LINE WEBTOON\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.webtoons.com/th/originals'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "print(driver.current_url)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 9): # 월요일 2 ~ 일요일 8\n",
    "\n",
    "    count = [47, 57, 54, 53, 50, 51, 57]\n",
    "\n",
    "    for j in range(16, count[i-2]+1): # 요일별 처음 ~ 끝\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, 0)\") \n",
    "\n",
    "        date_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/h2/a\"\"\")\n",
    "        date_button.click()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        title = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/div/p[1]\"\"\").text\n",
    "        author = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a/div/p[2]\"\"\").text\n",
    "\n",
    "        # 상세페이지 들어가기\n",
    "        detail_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"dailyList\"]/div[{i}]/ul/li[{j}]/a\"\"\")\n",
    "        detail_button.click()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 회차\n",
    "        req = requests.get(driver.current_url)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        episode = soup.find_all(class_='tx')[0].text.replace('#', '')\n",
    "\n",
    "        # 마지막연재일\n",
    "        last_date = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"episode_{episode}\"]/a/span[4]\"\"\").text\n",
    "        \n",
    "        # 첫화 보기\n",
    "        first_ep = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_btnEpisode\"]\"\"\")\n",
    "        first_ep.click()\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 팝업\n",
    "        try:\n",
    "            accept = driver.find_element(By.XPATH, \"\"\"/html/body/div[4]/div/div/p[2]/a[2]\"\"\")\n",
    "            accept.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 스크롤 끝까지 내리기\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 연재시작일\n",
    "        start_date = driver.find_element(By.XPATH, \"\"\"//*[@id=\"cbox_module_wai_u_cbox_content_wrap_tabpanel\"]/ul/li[1]/div[1]/div/div[3]/span[1]\"\"\").text\n",
    "        add.loc[len(add)] = [title, author, last_date, start_date]\n",
    "\n",
    "        print(i, j, title, last_date, start_date)\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 상세페이지 나오기\n",
    "        driver.back()\n",
    "        driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.to_csv('add_요일.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ฟรีทุกวัน(전체매일+웹툰)_연재시작일 및 마지막연재일**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = pd.DataFrame(columns=['title', 'author', 'last_date', 'start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.webtoons.com/th/originals\n",
      "ติดตามและอัปเดต การ์ตูน ออนไลน์ ฟรี | LINE WEBTOON\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.webtoons.com/th/originals'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "print(driver.current_url)\n",
    "print(driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528 ครัวแม่ดาชา ซีเคร็ทเซอร์วิส 12 มี.ค. 2017 13 ธ.ค. 2015\n",
      "529 ผจญป่วน ก๊วนจอมเวท 4 มี.ค. 2017 21 ก.พ. 2015\n",
      "530 วาดเล่นๆ ดันเป็นเรื่อง 17 ก.พ. 2017 4 พ.ย. 2016\n",
      "531 Capo เหมียวหง่าวหลุดโลก 14 ก.พ. 2017 31 ส.ค. 2015\n",
      "532 ไซด์คิกส์ ฮีโร่ตัวรอง 7 ก.พ. 2017 1 มิ.ย. 2015\n",
      "533 เล่าเรื่องพ่อ The Series 9 ม.ค. 2017 5 ธ.ค. 2016\n",
      "534 เกรียนเทพอย่างผมไม่มีแล้วนะค้าบ 11 ธ.ค. 2016 8 พ.ย. 2015\n",
      "535 แฟนเดย์..แฟนกันแค่วันเดียว 31 ส.ค. 2016 18 ส.ค. 2016\n",
      "536 Friendship เพื่อนกันนานเวอร์ 25 เม.ย. 2016 19 ต.ค. 2015\n",
      "537 สงกรานต์นี้มีเพื่อน 16 เม.ย. 2016 16 เม.ย. 2016\n",
      "538 อัศวินทะลุมิติ 13 เม.ย. 2016 12 ม.ค 2015\n",
      "539 กรุ๊ปเลือด บอกนิสัย 28 มี.ค. 2016 8 พ.ย. 2015\n",
      "540 สตาร์วอร์ส 6 มี.ค. 2016 15 พ.ย. 2015\n",
      "541 THE DESTROYER เกิด/ฆ่า/อมตะ 27 ก.พ. 2016 5 มี.ค. 2016\n",
      "542 Shewsheep กินทั้งวัน ฝันยังเคี้ยว 26 ม.ค. 2016 4 ม.ค 2016\n",
      "543 แมวขี้อ้อน . . . . . หมาขี้เหงา 16 ม.ค. 2016 16 พ.ค. 2015\n",
      "544 ชีวิตนี้ รสหวานขม 25 ธ.ค. 2015 3 พ.ค. 2016\n",
      "545 เลซซา มือปราบอสูร 26 พ.ย. 2015 19 ม.ค 2015\n",
      "546 ครัวแม่ดาชา 27 ต.ค. 2015 5 ม.ค 2016\n",
      "547 จิงเกิ้ลจังเกิ้ล เพื่อนป่าฮาเฮ 21 ต.ค. 2015 22 เม.ย. 2015\n",
      "548 ฝีแปรงแย้มยิ้ม : ภาพเก่าๆ ของฉัน 20 ก.ย. 2015 10 เม.ย. 2015\n",
      "549 ฮาเร็ม ซะเมื่อไหร่กันเล่า! 6 ส.ค. 2015 5 ก.พ. 2015\n",
      "550 ซุปเปอร์คุณพ่อ 29 มี.ค. 2015 11 ก.ค. 2015\n",
      "551 ฝีแปรงแย้มยิ้ม 9 มี.ค. 2015 24 พ.ย. 2014\n",
      "552 ธรรมดาไดอารี่ 8 ก.พ. 2015 19 เม.ย. 2015\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 553): \n",
    "\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[1]/div/ul/li[2]/a\"\"\")\n",
    "        button.click()\n",
    "    except:\n",
    "        driver.forward()\n",
    "        button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[1]/div/ul/li[2]/a\"\"\")\n",
    "        button.click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    title = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/div/p[1]\"\"\").text\n",
    "    author = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a/div/p[2]\"\"\").text\n",
    "    \n",
    "    # 상세페이지 들어가기\n",
    "    detail_button = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"content\"]/div[2]/div[2]/div/ul/li[{i}]/a\"\"\")\n",
    "    detail_button.click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 회차\n",
    "    req = requests.get(driver.current_url)\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    episode = soup.find_all(class_='tx')[0].text.replace('#', '')\n",
    "\n",
    "    # 마지막연재일\n",
    "    last_date = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"episode_{episode}\"]/a/span[4]\"\"\").text\n",
    "    \n",
    "    # 첫화 보기\n",
    "    first_ep = driver.find_element(By.XPATH, \"\"\"//*[@id=\"_btnEpisode\"]\"\"\")\n",
    "    first_ep.click()\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 팝업\n",
    "    try:\n",
    "        accept = driver.find_element(By.XPATH, \"\"\"/html/body/div[4]/div/div/p[2]/a[2]\"\"\")\n",
    "        accept.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 스크롤 끝까지 내리기\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 연재시작일\n",
    "    try:\n",
    "        start_date = driver.find_element(By.XPATH, \"\"\"//*[@id=\"cbox_module_wai_u_cbox_content_wrap_tabpanel\"]/ul/li[1]/div[1]/div/div[3]/span[1]\"\"\").text\n",
    "    except:\n",
    "        back_button = driver.find_element(By.XPATH, \"\"\"//*[@id=\"content\"]/div/div/a[1]\"\"\")\n",
    "        back_button.click()\n",
    "        start_date = driver.find_element(By.XPATH, f\"\"\"//*[@id=\"episode_1\"]/a/span[4]\"\"\").text\n",
    "\n",
    "    add.loc[len(add)] = [title, author, last_date, start_date]\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # 상세페이지 나오기\n",
    "    driver.back()\n",
    "    driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.to_csv('add_매일+.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **concat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('add_요일.csv')\n",
    "data2 = pd.read_csv('add_매일.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.concat([data1, data2])\n",
    "d.to_csv('crawling_total_add_date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>last_date</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ปฏิบัติการลับบุกโรงเรียนไฮโซ</td>\n",
       "      <td>AJ</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>21 ส.ค. 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ห้องนอนลับของเจ้าหญิงต้องสาป</td>\n",
       "      <td>Henie / HYERIM SUNG</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>12 ก.ย. 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ช่วยเปลี่ยนฉันที</td>\n",
       "      <td>ลีจีโฮ / โฮตี</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>13 ม.ค 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ชีวิตมหา’ลัยที่ฝันไว้..มันต้องไม่ใช่แบบนี้สิ!</td>\n",
       "      <td>Kai2536</td>\n",
       "      <td>17 ก.ย. 2023</td>\n",
       "      <td>28 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ใครลักจักรพรรดินี</td>\n",
       "      <td>Muhly / Pinku</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>22 พ.ค. 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title               author  \\\n",
       "0                   ปฏิบัติการลับบุกโรงเรียนไฮโซ                   AJ   \n",
       "1                   ห้องนอนลับของเจ้าหญิงต้องสาป  Henie / HYERIM SUNG   \n",
       "2                               ช่วยเปลี่ยนฉันที        ลีจีโฮ / โฮตี   \n",
       "3  ชีวิตมหา’ลัยที่ฝันไว้..มันต้องไม่ใช่แบบนี้สิ!              Kai2536   \n",
       "4                              ใครลักจักรพรรดินี        Muhly / Pinku   \n",
       "\n",
       "      last_date    start_date  \n",
       "0  18 ก.ย. 2023  21 ส.ค. 2023  \n",
       "1  18 ก.ย. 2023  12 ก.ย. 2022  \n",
       "2  18 ก.ย. 2023   13 ม.ค 2020  \n",
       "3  17 ก.ย. 2023  28 ต.ค. 2019  \n",
       "4  18 ก.ย. 2023  22 พ.ค. 2023  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = d.rename(columns={'title':'제목', 'author':'작가'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>작가</th>\n",
       "      <th>last_date</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>กลั้นน้ำตา</td>\n",
       "      <td>Pixel Ghost</td>\n",
       "      <td>17 ก.ย. 2023</td>\n",
       "      <td>22 ม.ค 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>นึกว่าเป็นอิเซไคธรรมดา</td>\n",
       "      <td>DOYOSAY / A-Jin</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>11 ก.ค. 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>นึกว่าเป็นอิเซไคธรรมดา</td>\n",
       "      <td>DOYOSAY / A-Jin</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>11 ก.ค. 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ร้องไห้เถิดเพคะ องค์ชาย</td>\n",
       "      <td>DuckDam</td>\n",
       "      <td>9 ส.ค. 2023</td>\n",
       "      <td>23 ก.พ. 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>ร้องไห้เถิดเพคะ องค์ชาย</td>\n",
       "      <td>DuckDam</td>\n",
       "      <td>9 ส.ค. 2023</td>\n",
       "      <td>23 ก.พ. 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Sweetie Calories ฟิตหุ่นลุ้นรัก</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24 ก.ย. 2021</td>\n",
       "      <td>9 ม.ค 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>เด็กห้องนี้ มีแปลก</td>\n",
       "      <td>ยอง ปากา</td>\n",
       "      <td>20 ก.พ. 2021</td>\n",
       "      <td>2 มี.ค. 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Sweetie Calories ฟิตหุ่นลุ้นรัก</td>\n",
       "      <td>JISARA</td>\n",
       "      <td>24 ก.ย. 2021</td>\n",
       "      <td>9 ม.ค 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>เด็กห้องนี้ มีแปลก</td>\n",
       "      <td>ยอง ปากา</td>\n",
       "      <td>20 ก.พ. 2021</td>\n",
       "      <td>2 มี.ค. 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>แฮปปี้ควอกก้า</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>12 ก.ย. 2023</td>\n",
       "      <td>29 ต.ค. 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>เว็บตูนอีเวนต์</td>\n",
       "      <td>WEBTOON</td>\n",
       "      <td>18 ก.ย. 2023</td>\n",
       "      <td>20 ธ.ค. 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>กลั้นน้ำตา</td>\n",
       "      <td>Pixel Ghost</td>\n",
       "      <td>17 ก.ย. 2023</td>\n",
       "      <td>22 ม.ค 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  제목               작가     last_date  \\\n",
       "8                      แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "27                    เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "30                        กลั้นน้ำตา      Pixel Ghost  17 ก.ย. 2023   \n",
       "46            นึกว่าเป็นอิเซไคธรรมดา  DOYOSAY / A-Jin  12 ก.ย. 2023   \n",
       "47            นึกว่าเป็นอิเซไคธรรมดา  DOYOSAY / A-Jin  12 ก.ย. 2023   \n",
       "57                     แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "79                    เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "113                    แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "130                   เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "149          ร้องไห้เถิดเพคะ องค์ชาย          DuckDam   9 ส.ค. 2023   \n",
       "150          ร้องไห้เถิดเพคะ องค์ชาย          DuckDam   9 ส.ค. 2023   \n",
       "165                    แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "185                   เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "214                   เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "235  Sweetie Calories ฟิตหุ่นลุ้นรัก              NaN  24 ก.ย. 2021   \n",
       "236               เด็กห้องนี้ มีแปลก         ยอง ปากา  20 ก.พ. 2021   \n",
       "245                    แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "262                   เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "287  Sweetie Calories ฟิตหุ่นลุ้นรัก           JISARA  24 ก.ย. 2021   \n",
       "288               เด็กห้องนี้ มีแปลก         ยอง ปากา  20 ก.พ. 2021   \n",
       "304                    แฮปปี้ควอกก้า          WEBTOON  12 ก.ย. 2023   \n",
       "324                   เว็บตูนอีเวนต์          WEBTOON  18 ก.ย. 2023   \n",
       "325                       กลั้นน้ำตา      Pixel Ghost  17 ก.ย. 2023   \n",
       "\n",
       "       start_date  \n",
       "8    29 ต.ค. 2019  \n",
       "27   20 ธ.ค. 2021  \n",
       "30    22 ม.ค 2017  \n",
       "46   11 ก.ค. 2023  \n",
       "47   11 ก.ค. 2023  \n",
       "57   29 ต.ค. 2019  \n",
       "79   20 ธ.ค. 2021  \n",
       "113  29 ต.ค. 2019  \n",
       "130  20 ธ.ค. 2021  \n",
       "149  23 ก.พ. 2022  \n",
       "150  23 ก.พ. 2022  \n",
       "165  29 ต.ค. 2019  \n",
       "185  20 ธ.ค. 2021  \n",
       "214  20 ธ.ค. 2021  \n",
       "235    9 ม.ค 2021  \n",
       "236  2 มี.ค. 2015  \n",
       "245  29 ต.ค. 2019  \n",
       "262  20 ธ.ค. 2021  \n",
       "287    9 ม.ค 2021  \n",
       "288  2 มี.ค. 2015  \n",
       "304  29 ต.ค. 2019  \n",
       "324  20 ธ.ค. 2021  \n",
       "325   22 ม.ค 2017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.duplicated(['제목'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = df.drop_duplicates(['제목'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 881 entries, 0 to 551\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   제목          881 non-null    object\n",
      " 1   작가          881 non-null    object\n",
      " 2   last_date   881 non-null    object\n",
      " 3   start_date  881 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 34.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_dup.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.read_csv('crawling_total_전처리완료_877_230918.csv')\n",
    "merge2 = df_dup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 23)\n",
      "(881, 4)\n"
     ]
    }
   ],
   "source": [
    "print(merge1.shape)\n",
    "print(merge2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merge1, merge2, on=['제목', '작가'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 877 entries, 0 to 876\n",
      "Data columns (total 25 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   제목          877 non-null    object \n",
      " 1   작가          877 non-null    object \n",
      " 2   장르(태국)      877 non-null    object \n",
      " 3   좋아요수        877 non-null    int64  \n",
      " 4   조회수         877 non-null    int64  \n",
      " 5   구독수         877 non-null    int64  \n",
      " 6   별점          877 non-null    float64\n",
      " 7   회차          877 non-null    int64  \n",
      " 8   국가          877 non-null    object \n",
      " 9   한국제목        593 non-null    object \n",
      " 10  한국작가명       593 non-null    object \n",
      " 11  회차(한국)      877 non-null    int64  \n",
      " 12  별점(한국)      593 non-null    float64\n",
      " 13  관심수(한국)     877 non-null    int64  \n",
      " 14  장르(한국)      593 non-null    object \n",
      " 15  해시태그(한국)    593 non-null    object \n",
      " 16  연재시작일       593 non-null    object \n",
      " 17  마지막연재일      593 non-null    object \n",
      " 18  완결여부        593 non-null    object \n",
      " 19  웹툰/시리즈구분    593 non-null    object \n",
      " 20  작가전작개수      877 non-null    int64  \n",
      " 21  OSMU여부      877 non-null    bool   \n",
      " 22  태국진출여부      877 non-null    bool   \n",
      " 23  last_date   822 non-null    object \n",
      " 24  start_date  822 non-null    object \n",
      "dtypes: bool(2), float64(2), int64(7), object(14)\n",
      "memory usage: 159.4+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 누락값 결측치 채우기\n",
    "merged_df['last_date'] = merged_df['last_date'].fillna(method = 'ffill')\n",
    "merged_df['start_date'] = merged_df['start_date'].fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={'last_date':'마지막연재일(태국)', 'start_date':'연재시작일(태국)', '연재시작일':'연재시작일(한국)', '마지막연재일':'마지막연재일(한국)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['제목', '작가', '장르(태국)', '좋아요수', '조회수', '구독수', '별점', '회차', '국가', '한국제목',\n",
       "       '한국작가명', '회차(한국)', '별점(한국)', '관심수(한국)', '장르(한국)', '해시태그(한국)',\n",
       "       '연재시작일(한국)', '마지막연재일(한국)', '완결여부', '웹툰/시리즈구분', '작가전작개수', 'OSMU여부',\n",
       "       '태국진출여부', '마지막연재일(태국)', '연재시작일(태국)'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['제목', '작가', '장르(태국)', '좋아요수', '조회수', '구독수', '별점', '회차', '연재시작일(태국)', '마지막연재일(태국)', '국가', \n",
    "                       '한국제목', '한국작가명', '회차(한국)', '별점(한국)', '관심수(한국)', '장르(한국)', '해시태그(한국)', \n",
    "                       '연재시작일(한국)', '마지막연재일(한국)', '완결여부', '웹툰/시리즈구분', '작가전작개수', 'OSMU여부', '태국진출여부']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('최종데이터셋.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
